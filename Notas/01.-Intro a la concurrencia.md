# Introducción a la concurrencia

## 1.- Definiciones

Entendemos por **programa** a un conjunto de datos, asignaciones e instrucciones que se ejecutan secuencialmente en un procesador y acceden a datos almacenados en distintos niveles de memotia. Un programa **concurrente** es a su vez un conjunto de programas secuenciales independientes que _pueden_ ejecutarse en paralelo. A cada uno de estos programas secuenciales los llamamos **proceso**.

Es conveniente explicitar la distinción entre _concurrencia_ y _paralelismo_. Un **sistema paralelo** consiste de varios programas corriendo _simultáneamente_ en distintos núcleos del procesador. Un programa concurrente puede ejecutar todos sus procesos en simultáneo también, pero utiliza _multitasking_ para poder ejecutar varios programas en el mismo procesador.

Llamamos **multitasking** a la capacidad de ejecutar múltiples procesos de forma concurrente en el mismo periodo de tiempo. El _scheduler_ del sistema operativo se encarge de manejar este proceso. Para utilizar eficientemente el multitasking, algunos lenguajes de programación proveen el **multithreading**, que es la abstracción que permite manejar varios hilos de ejecución concurrentes.

Los programas concurrentes se enfrentan principalmente a dos desafíos. Por un lado, la necesidad de **sincronizar** sus procesos temporalmente para garantizar el orden de algunas operaciones. Por el otro, la necesidad de **comunicar** datos entre los distintos hilos de ejecución de forma segura.

Para entender mejor el orden de ejecución de operaciones en programas concurrentes, se analizan los procesos en base a sus **instrucciones atómicas**. Una instrucción atómica es una que, o se ejecuta en su totalidad, o no se ejecuta en lo absoluto. O sea, es una instrucción indivisible. La **ejecución** de un programa concurrente es entonces una secuencia arbitraria de instrucciones atómicas de los procesos que lo componen.

## 2.- Modelos de concurrencia

Existen varios modelos que nos ayudarán a trabajar ordenadamente con la concurrencia.

- El primero es un **estado mutable compartido**. Como los procesos son independientes en suu ejecución, lo más problable es que también tengan sectores de ejecución que son completamente independientes uno de otro. Pero parte importante de la concurrencia es tener varios procesos trabajando en común hacia una misma tarea. Necesitamos entonces que los procesos _compartan cierto estado_, y que además dicho estado _sea mutable_. Para evitar problemas de acceso concurrente (como que un proceso lea parte del estado que otro proceso está escribiendo), cualquier proceso que quiera acceder al estado compartido deberá esperar a que todos los otros procesos que solicitaron acceso antes terminen de utilizarlo. Esto garantiza que el estado compartido siemore va a ser válido.
- Otro modelo más sencillo es el **paralelismo fork-join**. Un proceso dado puede realizar todas las preparaciones necesarias para realizar cierta tarea que se puede beneficiar de la concurrencia, y luego _invocar_ otro proceso (fork) para que realice dicha tarea. El proceso original puede seguir ejecutándose hasta el momento en que necesite el resultado de la operación, y entonces espera al proceso derivado a que termine y se una (join). Si bien este modelo es más sencillo al no haber comunicación entre los procesos, es más limitado.
- Otro modelo que sí permite la comunicación entre procesos es el de **canales y mensajes**. Los distintos procesos establecen un canal de comunicación (puede ser una queue, memoria compartida, etc.) por el cual enviarse _mensajes_. Una vez un proceso envía un mensaje (que puede ser datos, objetos, instrucciones, etc.) ya no es responsable del mismo, es el proceso que recibe el mensaje quien se hace responsable. De forma análoga a la programación orientada a objetos, donde los objetos interactúan entre sí por medio de mensajes, los distintos procesos también interactúan entre sí utilizando varios tipos de mensajes.
- Existen otros modelos, como la **programación asincrónica** o el modelo de **actores**, que son populares en ciertas aplicaciones. Serán estudiados a su debido tiempo.

## 3.- Threads ~ Introducción

Los _threads_ son una abstracción que permite crear y manejar programas concurrentes. Los threads, como su nombre lo indica, representan distintos _hilos de ejecución_ dentro del mismo programa. Comparten los recursos del proceso padre (code, data, archivos), pero cuentan cada uno con su propia iinformación de estado (registros, stack, PC). Más adelante se verán a detalle sus características, capacidades y limitaciones.
